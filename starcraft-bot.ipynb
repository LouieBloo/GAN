{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import bwapiEnums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputUnitCount = 256\n",
    "outputUnitCount = 256\n",
    "output_sequence_length = 5\n",
    "unitTypeTextVectorizationLayer = keras.layers.TextVectorization(output_sequence_length=output_sequence_length, vocabulary=bwapiEnums.allUnits)\n",
    "unitActionsTextVectorizationLayer = keras.layers.TextVectorization(output_sequence_length=output_sequence_length, vocabulary=bwapiEnums.unitActions)\n",
    "unitOrdersTextVectorizationLayer = keras.layers.TextVectorization(output_sequence_length=output_sequence_length, vocabulary=bwapiEnums.unitOrders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layers\n",
    "unitTypeInput = layers.Input(shape=(inputUnitCount,), dtype=tf.string, name='UnitTypeInput')\n",
    "unitOrderInput = layers.Input(shape=(inputUnitCount,), dtype=tf.string, name='UnitOrderInput')\n",
    "positionInput = layers.Input(shape=(inputUnitCount, 2), dtype=tf.float32, name='PositionInput')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unitTypeVectorized = layers.Lambda(lambda x: unitTypeTextVectorizationLayer(x))(unitTypeInput)\n",
    "#unitTypeVectorized = unitTypeTextVectorizationLayer(unitTypeInput)\n",
    "# Vectorize the unit type and unit order inputs\n",
    "unitTypeVectorized_list = [unitTypeTextVectorizationLayer(unitTypeInput[:, i]) for i in range(inputUnitCount)]\n",
    "unitOrderVectorized_list = [unitOrdersTextVectorizationLayer(unitOrderInput[:, i]) for i in range(inputUnitCount)]\n",
    "\n",
    "# Stack the vectorized outputs back to rank-2 tensors\n",
    "unitTypeVectorized = layers.Concatenate(axis=1)(unitTypeVectorized_list)\n",
    "unitOrderVectorized = layers.Concatenate(axis=1)(unitOrderVectorized_list)\n",
    "\n",
    "# Reshape the stacked outputs\n",
    "unitTypeVectorized = layers.Reshape((inputUnitCount, -1))(unitTypeVectorized)\n",
    "unitOrderVectorized = layers.Reshape((inputUnitCount, -1))(unitOrderVectorized)\n",
    "\n",
    "# Convert the vectorized outputs to float32\n",
    "unitTypeVectorized = tf.cast(unitTypeVectorized, tf.float32)\n",
    "unitOrderVectorized = tf.cast(unitOrderVectorized, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine the vectorized inputs and position input\n",
    "combinedInputs = layers.Concatenate(axis=-1)([unitTypeVectorized, unitOrderVectorized, positionInput])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more layers as needed for your specific use case\n",
    "hiddenLayer = layers.Dense(inputUnitCount*10, activation='relu')(combinedInputs)\n",
    "\n",
    "#output_shape = (inputUnitCount, len(bwapiEnums.unitActions))\n",
    "unitActionOutputLayer = layers.Dense(len(bwapiEnums.unitActions), activation='softmax')(hiddenLayer)\n",
    "#unitActionOutputLayer = layers.Reshape(target_shape=output_shape)(unitActionOutputLayer)\n",
    "\n",
    "unitOrderPositionOutputLayer = layers.Dense(2, activation='relu')(hiddenLayer)\n",
    "model = keras.models.Model(inputs=[unitTypeInput, unitOrderInput, positionInput], outputs=[unitActionOutputLayer,unitOrderPositionOutputLayer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = np.random.rand(256, 2)\n",
    "unitTypes = np.random.choice(bwapiEnums.allUnits,size=256)\n",
    "unitOrders = np.random.choice(bwapiEnums.unitOrders,256)\n",
    "\n",
    "# Combine the input data into a single array with multiple dimensions\n",
    "inputData = [np.array([unitTypes]), np.array([unitOrders]), np.array([position])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EEFF0F6D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 13s 13s/step\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction using the model\n",
    "prediction = model.predict(inputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14660926 0.1344882  0.14023484 0.15078779 0.14203045 0.13725783\n",
      " 0.14859161]\n",
      "['patrol', 'patrol', 'patrol', 'train', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'train', 'train', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'train', 'train', 'train', 'train', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'train', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'train', 'patrol', 'train', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'train', 'train', 'train', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'train', 'patrol', 'train', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'train', 'patrol', 'train', 'patrol', 'patrol', 'patrol', 'patrol']\n"
     ]
    }
   ],
   "source": [
    "#print(prediction[0])\n",
    "print(prediction[0][0][0])\n",
    "predictedActions = []\n",
    "for i in range(inputUnitCount):\n",
    "    seq = prediction[0][:, i] # Get the predicted sequence for the i-th input unit\n",
    "    idx = np.argmax(seq) # Get the index of the highest predicted probability for the sequence\n",
    "    action = unitActionsTextVectorizationLayer.get_vocabulary()[idx] # Look up the corresponding string in the vocabulary\n",
    "    predictedActions.append(action)\n",
    "\n",
    "# Print the predicted actions\n",
    "print(predictedActions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13441335 0.15241541\n",
      "0.0 0.014810957\n",
      "0.0006090391\n"
     ]
    }
   ],
   "source": [
    "print(np.min(prediction[0]), np.max(prediction[0]))\n",
    "print(np.min(prediction[1]), np.max(prediction[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb75ca023a83b6caf8f1f559b19e7b17d171fd17528d93a5502dd82e32e6be3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
